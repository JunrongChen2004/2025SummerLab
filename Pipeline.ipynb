{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import cv2\n",
    "model = load_model(\"/teamspace/studios/this_studio/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\", \"/teamspace/studios/this_studio/GroundingDINO/weights/groundingdino_swint_ogc.pth\")\n",
    "IMAGE_PATH = \"images/apple_5_1.png\"\n",
    "TEXT_PROMPT = \"purple apples. \"\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "    \n",
    "image_source, image = load_image(IMAGE_PATH)\n",
    "    \n",
    "boxes, logits, phrases = predict(\n",
    "    model=model,\n",
    "    image=image,\n",
    "    caption=TEXT_PROMPT,\n",
    "    box_threshold=BOX_TRESHOLD,\n",
    "    text_threshold=TEXT_TRESHOLD\n",
    ")\n",
    "    \n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "cv2.imwrite(\"annotated_image.jpg\", annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.32.2)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.47.0.dev0)\n",
      "Requirement already satisfied: importlib-metadata in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (2.1.2+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.32.2)\n",
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.47.0.dev0)\n",
      "Requirement already satisfied: importlib-metadata in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (2.1.2+cu121)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (2.1.2+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers transformers\n",
    "!pip install accelerate\n",
    "!pip install diffusers accelerate transformers\n",
    "\n",
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with standard code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(input_str: str) -> (int, str):\n",
    "    \"\"\"\n",
    "    Parses a string in the format \"<number> <word>s\" and returns a tuple:\n",
    "    - the number as an int\n",
    "    - the singular form of the word (by removing a trailing 's')\n",
    "    \n",
    "    Example:\n",
    "        input: \"8 animals\"\n",
    "        output: (8, \"animal\")\n",
    "    \"\"\"\n",
    "    # Split the input string into two parts.\n",
    "    parts = input_str.split()\n",
    "    if len(parts) != 2:\n",
    "        raise ValueError(\"Input must be in the format '<number> <word>s'\")\n",
    "    \n",
    "    # Convert the first part to an integer.\n",
    "    try:\n",
    "        number = int(parts[0])\n",
    "    except ValueError:\n",
    "        raise ValueError(\"The first part of the input must be an integer.\")\n",
    "    \n",
    "    # Get the word and remove a trailing 's' if present to singularize.\n",
    "    word = parts[1]\n",
    "    if word.endswith('s'):\n",
    "        word = word[:-1]\n",
    "    \n",
    "    return number, word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"/teamspace/studios/this_studio/GroundingDINO/images/apples_5.png\"\n",
    "config_path = \"/teamspace/studios/this_studio/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "weight_path = \"/teamspace/studios/this_studio/GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "input_prompt = \"5 apples\"\n",
    "number, text_prompt = parse_input(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "def generate_image(prompt: str, output_path: str = target_dir):\n",
    "    # Choose device: use CUDA if available, otherwise CPU (note: generation will be slower on CPU)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the stable diffusion pipeline\n",
    "    model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if device==\"cuda\" else torch.float32)\n",
    "    pipe = pipe.to(device)\n",
    "    \n",
    "    # Generate image from the prompt\n",
    "    result = pipe(prompt)\n",
    "    image = result.images[0]\n",
    "    \n",
    "    # Save the generated image\n",
    "    image.save(output_path)\n",
    "    print(f\"Image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def run_grounding_dino(image_path: str,\n",
    "                       text_prompt: str,\n",
    "                       config_path: str,\n",
    "                       weight_path: str,\n",
    "                       box_threshold: float = 0.35,\n",
    "                       text_threshold: float = 0.25,\n",
    "                       output_path: str = \"annotated_image.jpg\", num: int = 0) -> bool:\n",
    "    \"\"\"\n",
    "    Run GroundingDINO on an image, save an annotated output,\n",
    "    and return whether a detection was made.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "        text_prompt (str): Text prompt for detection.\n",
    "        config_path (str): Path to the model config file.\n",
    "        weight_path (str): Path to the model weights.\n",
    "        box_threshold (float): Threshold for the bounding box predictions.\n",
    "        text_threshold (float): Threshold for text confidence.\n",
    "        output_path (str): File path to save the annotated image.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if at least one detection is made, False otherwise.\n",
    "    \"\"\"\n",
    "    # Load the model.\n",
    "    model = load_model(config_path, weight_path)\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    \n",
    "    # Load the image (both original and processed).\n",
    "    image_source, image = load_image(image_path)\n",
    "    \n",
    "    # Run prediction.\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    # Debug prints (optional, can be removed after verification)\n",
    "    print(\"boxes type:\", type(boxes))\n",
    "    if hasattr(boxes, \"shape\"):\n",
    "        print(\"boxes shape:\", boxes.shape)\n",
    "    else:\n",
    "        print(\"boxes:\", boxes)\n",
    "    print(\"logits:\", logits)\n",
    "    print(\"phrases:\", phrases)\n",
    "    \n",
    "    # Annotate image.\n",
    "    annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "    cv2.imwrite(output_path, annotated_frame)\n",
    "    \n",
    "    # Return True if any detections are present.\n",
    "    if isinstance(boxes, torch.Tensor):\n",
    "        result = boxes.shape[0] > 0\n",
    "    elif isinstance(boxes, (list, tuple)):\n",
    "        result = len(boxes) > 0\n",
    "    else:\n",
    "        result = False\n",
    "        \n",
    "    if result == True and len(phrases) == num:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation attempt #1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23128e1fc0234de2b7100bcf7067df5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80b4145237542529178f14aec6ceceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /teamspace/studios/this_studio/GroundingDINO/images/apples_5.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "boxes type: <class 'torch.Tensor'>\n",
      "boxes shape: torch.Size([5, 4])\n",
      "logits: tensor([0.8040, 0.7802, 0.7986, 0.7906, 0.7980])\n",
      "phrases: ['apple', 'apple', 'apple', 'apple', 'apple']\n",
      "Detection successful! Exiting loop.\n"
     ]
    }
   ],
   "source": [
    "# First, parse the input prompt.\n",
    "number, text_prompt = parse_input(input_prompt)\n",
    "\n",
    "# Update the prompt if needed for generation (ensure proper spacing)\n",
    "prompt = f\"a picture of {input_prompt}\"  # e.g., \"a picture of 5 apples\"\n",
    "\n",
    "attempt = 1\n",
    "while True:\n",
    "    print(f\"\\nGeneration attempt #{attempt}\")\n",
    "    \n",
    "    # Generate a new image using Stable Diffusion.\n",
    "    generate_image(prompt)\n",
    "    \n",
    "    # Run detection using GroundingDINO on the generated image.\n",
    "    detection = run_grounding_dino(\n",
    "        image_path=target_dir,\n",
    "        text_prompt=text_prompt,\n",
    "        config_path=config_path,\n",
    "        weight_path=weight_path,\n",
    "        box_threshold=0.2,      # Adjust threshold values as needed\n",
    "        text_threshold=0.15,\n",
    "        output_path=\"annotated_image.jpg\",\n",
    "        num=number\n",
    "    )\n",
    "    \n",
    "    # Check if detection was successful.\n",
    "    if detection:\n",
    "        print(\"Detection successful! Exiting loop.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"No detection found. Regenerating image...\")\n",
    "        attempt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with LLM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "def generate_image(prompt: str, output_path: str = f\"{target_dir}{file_name}_{attempt}.png\"):\n",
    "    # Choose device: use CUDA if available, otherwise CPU (note: generation will be slower on CPU)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the stable diffusion pipeline\n",
    "    model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if device==\"cuda\" else torch.float32)\n",
    "    pipe = pipe.to(device)\n",
    "    \n",
    "    # Generate image from the prompt\n",
    "    result = pipe(prompt)\n",
    "    image = result.images[0]\n",
    "    \n",
    "    # Save the generated image\n",
    "    image.save(output_path)\n",
    "    print(f\"Image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import torch\n",
      "import clip\n",
      "from PIL import Image\n",
      "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
      "import cv2\n",
      "\n",
      "def verify_image(image_path, text_prompt, attempt):\n",
      "    \"\"\"\n",
      "    Verifies whether the image matches the text_prompt using GroundingDINO and CLIP.\n",
      "\n",
      "    Args:\n",
      "        image_path (str): Path to the image file.\n",
      "        text_prompt (str): Text prompt for verification.\n",
      "        attempt (int): Attempt number for naming the annotated image.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing two booleans:\n",
      "            - GroundingDINO_result (bool): True if GroundingDINO verification passes, False otherwise.\n",
      "            - CLIP_result (bool): True if CLIP verification passes, False otherwise.\n",
      "    \"\"\"\n",
      "\n",
      "    # GroundingDINO verification\n",
      "    GroundingDINO_result = False\n",
      "    try:\n",
      "        model = load_model(\"groundingdino/config/GroundingDINO_SwinT_OGC.py\", \"weights/groundingdino_swint_ogc.pth\")\n",
      "        BOX_THRESHOLD = 0.35\n",
      "        TEXT_THRESHOLD = 0.25\n",
      "        \n",
      "        words = text_prompt.split()\n",
      "        if len(words) == 1:\n",
      "            TEXT_PROMPT = words[0]\n",
      "        elif len(words) == 2:\n",
      "            TEXT_PROMPT = words[1]\n",
      "        elif len(words) == 3:\n",
      "            TEXT_PROMPT = words[2]\n",
      "        else:\n",
      "            TEXT_PROMPT = words[-1]\n",
      "\n",
      "        image_source, image = load_image(image_path)\n",
      "\n",
      "        boxes, logits, phrases = predict(\n",
      "            model=model,\n",
      "            image=image,\n",
      "            caption=TEXT_PROMPT + \".\",\n",
      "            box_threshold=BOX_THRESHOLD,\n",
      "            text_threshold=TEXT_THRESHOLD\n",
      "        )\n",
      "        \n",
      "        # Count Verification for GroundingDINO\n",
      "        if len(words) >= 1 and words[0].isdigit():\n",
      "            expected_count = int(words[0])\n",
      "            actual_count = len(boxes)\n",
      "            GroundingDINO_result = (actual_count == expected_count)\n",
      "        else:\n",
      "             GroundingDINO_result = True\n",
      "\n",
      "        annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
      "        cv2.imwrite(f\"{text_prompt}_{attempt}_annotated.png\", annotated_frame)\n",
      "\n",
      "\n",
      "    except Exception as e:\n",
      "        print(f\"GroundingDINO error: {e}\")\n",
      "        GroundingDINO_result = False\n",
      "\n",
      "    # CLIP verification\n",
      "    CLIP_result = False\n",
      "    try:\n",
      "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
      "        model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
      "\n",
      "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
      "\n",
      "        words = text_prompt.split()\n",
      "        if len(words) == 1:\n",
      "            text_input = clip.tokenize([words[0]]).to(device)\n",
      "        elif len(words) == 2:\n",
      "             text_input = clip.tokenize([words[0] + \" \" + words[1]]).to(device)\n",
      "        elif len(words) == 3:\n",
      "            text_input = clip.tokenize([words[1] + \" \" + words[2]]).to(device)\n",
      "        else:\n",
      "            text_input = clip.tokenize([words[-1]]).to(device)\n",
      "\n",
      "        with torch.no_grad():\n",
      "            image_features = model.encode_image(image)\n",
      "            text_features = model.encode_text(text_input)\n",
      "\n",
      "            logits_per_image, logits_per_text = model(image, text_input)\n",
      "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
      "            \n",
      "            CLIP_result = (probs[0][0] > 0.5) # Set a threshold to determine if it matches\n",
      "\n",
      "    except Exception as e:\n",
      "        print(f\"CLIP error: {e}\")\n",
      "        CLIP_result = False\n",
      "\n",
      "    return GroundingDINO_result, CLIP_result\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=f\"\"\"\n",
    "You are a helpful coding expert. You will receive a text prompt and an image. Write a Python function named verify_image that takes an image path as its only argument and verifies whether the image matches the text_prompt {text_prompt} using two tools:\n",
    "\n",
    "GroundingDINO: Verify that the objects in the image match the object(s) specified in the prompt (including the count, if provided). Additionally, save the annotated image using file name \"{text_prompt}_{attempt}_annotated.png\" produced by GroundingDINO.\n",
    "For the TEXT_PROMPT variable in groundingDINO, only the Object word should be take in. The format of the prompt will be explained later.\n",
    "CLIP: Verify that the attributes in the image match the attribute(s) specified in the prompt.\n",
    "Text Prompt Format:\n",
    "\n",
    "The prompt may include a number indicating count, an adjective for attributes, and a noun for objects.\n",
    "If the prompt consists of three tokens and the first token is numeric, interpret them as:\n",
    "Count: The number of objects expected.\n",
    "Attribute: The descriptive adjective.\n",
    "Object: The noun representing the object.\n",
    "If the prompt contains two words:\n",
    "If the first token is numeric, treat it as the count and the second as the object.\n",
    "Otherwise, treat the first token as the attribute and the second as the object.\n",
    "If the prompt contains one word only, treat it as the object.\n",
    "If the prompt contains three words, treat the first token as the count and the second as the attribute and the third as the object\n",
    "\n",
    "Your function must take in three inputs: image_path, text_prompt, attempt (for the naming of the annotated image)\n",
    "Your function must be fully functional and verified to work correctly. Output only the function code without any extra explanations.\n",
    "\n",
    "Example usage for GroundingDINO:\n",
    "\"from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import cv2\n",
    "\n",
    "model = load_model(\"groundingdino/config/GroundingDINO_SwinT_OGC.py\", \"weights/groundingdino_swint_ogc.pth\")\n",
    "IMAGE_PATH = \"animal.png\"\n",
    "TEXT_PROMPT = \"animal.\"\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.25\n",
    "\n",
    "image_source, image = load_image(IMAGE_PATH)\n",
    "\n",
    "boxes, logits, phrases = predict(\n",
    "    model=model,\n",
    "    image=image,\n",
    "    caption=TEXT_PROMPT,\n",
    "    box_threshold=BOX_THRESHOLD,\n",
    "    text_threshold=TEXT_THRESHOLD\n",
    ")\n",
    "\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "cv2.imwrite(\"annotated_image.jpg\", annotated_frame)\"\n",
    "\n",
    "Example usage for CLIP:\n",
    "\"import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\"\n",
    "    \"\"\",\n",
    "    )\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (6.1.1)\n",
      "Requirement already satisfied: regex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.66.6)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-u_p7hcr7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-u_p7hcr7\n",
      "\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (24.1)\n",
      "Requirement already satisfied: regex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (4.66.6)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (2.1.2+cu121)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from clip==1.0) (0.16.2+cu121)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (2024.9.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->clip==1.0) (2.1.0)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->clip==1.0) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "target_dir = \"\"\n",
    "file_name = \"apple_5\"\n",
    "config_path = \"/teamspace/studios/this_studio/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "weight_path = \"/teamspace/studios/this_studio/GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "text_prompt = \"5 red apples\"\n",
    "attempt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "def prompt_revise(text_prompt):\n",
    "    client = genai.Client(api_key=\"")\n",
    "    prompt_r_response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=f\"\"\"\n",
    "        You are a helpful expert in generating prompts. The following text prompt are the prompt that will act as the prompt for stable diffusion image generation: {text_prompt}\n",
    "        But the generation image now does not match the ground truth of the text prompt. Your goal is to revise the text prompt and make it clearer for better stable diffusion image generations.\n",
    "        Output only the revised prompt without any extra explanations.\n",
    "        \"\"\",)\n",
    "    return prompt_r_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: 401 Client Error. (Request ID: Root=1-67e3213e-065ad0bc08cedbff662a91c6;fee4d49d-d929-4d95-bf46-7d817cf1258f)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/api/models/stabilityai/stable-diffusion-2-1-base.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid credentials in Authorization header.\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation attempt #1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63700de67174b92a7f975cdc75f2b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf804b446f744ca6b783a0f1dda080d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to apple_5_1.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "Detection successful! Exiting loop.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "prompt = f\"a picture of {text_prompt}\"  # e.g., \"a picture of 5 apples\"\n",
    "code_str = response.text.strip()\n",
    "if code_str.startswith(\"```\"):\n",
    "    # Remove the starting ``` (and optional language identifier) and the ending ```\n",
    "    code_str = re.sub(r'^```(?:python)?\\s*', '', code_str)\n",
    "    code_str = re.sub(r'\\s*```$', '', code_str)\n",
    "\n",
    "# Execute the cleaned code to define verify_image.\n",
    "exec(code_str)\n",
    "while True:\n",
    "    print(f\"\\nGeneration attempt #{attempt}\")\n",
    "    \n",
    "    # Generate a new image using Stable Diffusion.\n",
    "    generate_image(prompt, f\"{target_dir}{file_name}_{attempt}.png\")\n",
    "    \n",
    "    # Verify the generated image using the LLM-provided function.\n",
    "    # Here, we assume that `number` corresponds to the expected number of apples.\n",
    "    detection = verify_image(image_path=f\"{target_dir}{file_name}_{attempt}.png\", text_prompt = text_prompt, attempt = attempt)\n",
    "    # Check if verification was successful.\n",
    "    if detection:\n",
    "        print(\"Detection successful! Exiting loop.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Mismatch detected. Regenerating image...\")\n",
    "        attempt += 1\n",
    "        text_prompt = prompt_revise(text_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
